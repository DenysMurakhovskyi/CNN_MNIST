{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import PIL\n",
    "import os, pathlib\n",
    "import numpy as np\n",
    "\n",
    "from application.utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = trainX[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Data shape: {sample_image.shape}')\n",
    "image = PIL.Image.fromarray(sample_image)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('S:/PyProj/CNN_MNIST_PYQT/test/test_files')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_images = pathlib.Path(os.getcwd()).parent.resolve() / 'test/test_files'\n",
    "path_to_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADICAIAAADgCn1NAAAEEUlEQVR4nO3dzXKbQBAA4SGV939l5YCLyLLMLj+CnZ7+rj7ERTPLApE1PR6PENffu38BmmmaVn56/Tj9ufjf08UMDGfgS60v4J9gYDgDwxn4TNevwE0GhjMwnIEv5YMOnczApxlwhxUGxjPwOcYc3zDwlW55M2tgOAPDGfgEw16Aw8B4Bj5q5PENA1/mrv/caGA4Ax8y+PocBsYz8H7jj28YGM/AV7jx80EG3ql/fb73018GhjMwnIH3yLI+h4HxDAxn4M1SPN9YGBjOwNvkGt8w8CZb696+hQ4D90s3uzMDwxkYzsBdkq7PYWA8/9Jd247xHWH/PHOCG/IuzjMDN4wzi/sYuMEJ1quhht7Aa7KPbxgYz9uk9wCzO3OCTzbUBTgMjGfgNzDrcxgYz8BwBn51ZH0ebYcVBsYzMJyBvyHtn2cGhjPwf7zxDQOfaMAtdBh4gRzfMDCegSO44xsGjr66Y15fexi4LW/dMPBZi/OwJ0H1wE3DlutUOjB4b7WoG/jcvdWw50rdwEUUDcy+NXpWNHDTS93mCTHs2VAxcOrP+25VLvC+xXnYPVRTrcB5O+1WK3CPvKvxWwb+5m3d1HNfKPDnOo089FUCf+7Gd+S6USfwbqnX5ygSuM5zq59KBG7G2113/NOiRODsy+wRJQLvBjgz+IHzvic4BT/w56Q4M+CBi49v4AOLHPjgFgmwwwp24KYj63OWtR0b2KvvDBtYM2Zgx3fBDHwcY4cVyMAXjG+iBQAVeJqmnsnDTGcPVOBOzfkjnQGcwJ1VEq2up+AE7lGtbmACX7mo5jpLCIFdnFekD3z9hijXFix94J65fDweNcc3AIFPf6wBe8yZPrDWpfzms/6rYK5p+wQn+JtcG6ge+QI7vpvkC6xNUl6D75JxScg3wRmP8o3yBf4c3g4rqEu0U74ATrB1nwED65mBv8AeQS9SXoOTHutbOMFwBoYzMJyBI7g7rDAwnoHhDAxnYDgDwxmY+ZZwYWA4A8MZuC3vU44wMF71wOwdVhgYz8Bw1QN/7vs6BlE9MJ6B4QwMVz1w8zYp+31U9cB4BoYzcIO3SYllv772KB24AgPDGRjOwGuy77DCwHgGhjMwnIHhDAxn4F8BttBRM3DnF6QxpPwrO5v81rJIY8IEr0xkkYorpnRXGr8D68V8QH77VUcMPNTYDXh8nj0fq7e/KmGJLutlEt4OhhO8ze2Ha+tffDIw0HNTl2ig5wkxMNPS2MBwBmZaLsMGBnKTRfZyW2RguBHfJg1ya864HR/xQceYBu+d6WVDLtN03TH8+eJo/VVSGBjPTRacgeEMDGdgOAPDGRjOwHAGhjMwnIHhDAxnYDgDwxkYzsBwBoYzMJyB4QwMZ2A4A8MZGM7AcAaGMzDcPyNCD8LZlfhtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x200>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image_own = PIL.Image.open(path_to_images / 'image_1.png')\n",
    "sample_image_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAW0lEQVR4nM2QMQrAMAwDlZL/f1kdOsSS5aVQqKckx1kiwA+GPOfLWb04BNYIRTRIEcPaCZooUAMVUjWBnR3IwMvaJmLnnmaukLqnlZb5HrYPejL7c2mSYK74/dx80RAo4hKp9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_own_image = Utils.get_formatted_image(sample_image_own, as_ndarray=False)\n",
    "processed_own_image.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape dataset to satisfy Conv2D layer requirements, normalize the data\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# one hot encode target values using keras build-in method\n",
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.1328 - accuracy: 0.9588\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0452 - accuracy: 0.9860\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0313 - accuracy: 0.9899\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0227 - accuracy: 0.9929\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0160 - accuracy: 0.9951\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 47s 25ms/step - loss: 0.0089 - accuracy: 0.9971\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "> 99.090\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=1)\n",
    "# save model\n",
    "model.save('digit_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset is 99.090\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on test dataset is {(acc * 100.0):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('digit_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_np = Utils.get_formatted_image(sample_image_own).reshape((28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([(np.array(sample_image_np) / 255).astype('int')]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.4149510e-16, 1.7621629e-18, 1.0000000e+00, 7.2323857e-15,\n",
       "        5.1674510e-23, 7.6324681e-27, 1.6443204e-20, 2.0735682e-15,\n",
       "        3.8898346e-10, 7.3967779e-24]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([(np.array(sample_image_np) / 255).astype('int')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX = prep_pixels(trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras as tk\n",
    "tk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
